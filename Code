from sklearn.datasets import load_boston
import numpy as np

x,y=load_boston(return_x_y=True)

x.shape

y.shape

x

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.model_selection import cross_val_score

lr=LinearRegression()
dt=DecisionTreeRegressor()
svr=SVR()

estimators=[('lr',lr),('dt',dt),('svr',svr)]

for estimator in estimators:
   score=cross_val_score(estimator[1],x,y,scoring='r2',cv=10)
   print(estimator[0],np.round(np.mean(scores),2))
   
from sklearn.ensemble import VotingRegressor

vr=VotingRegressor(estimators)
scores=cross_val_score(vr,x,y,scoring='r2',cv=10)
print("Voting Regressor",np.round(np.mean(scores),2))


#now i will experiment with weights i.e i have three models so i will assign different weights to different models and test them.

for i in range(1,4):
   for j in range(1,4):
       for k in range(1,4):
           vr=VotingRegressor(estimators,weights=[i,j,k])
           scores=cross_val_score(vr,x,y,scoring='r2',cv=10)
           print("For i={},j={},k={}".format(i,j,k),np.round(np.mean(scores),2))
           
           
           
#I can also apply voting regressor on the same algorithm having different attributes(but why?=>to improve the R2 score or its working)
#using same algorithm

dt1=DecisionTreeRegressor(max_depth=1)
dt2=DecisionTreeRegressor(max_depth=3)
dt3=DecisionTreeRegressor(max_depth=5)
dt4=DecisionTreeRegressor(max_depth=7)
dt5=DecisionTreeRegressor(max_depth=None)

estimators=[('dt1',dt1),('dt2',dt2),('dt3',dt3),('dt4',dt4),('dt5',dt5)]

for estimator in estimators:
     scores=cross_val_score(estimator[1],x,y,scoring='r2',cv=10)
     print(estimator[0],np.round(np.mean(scores),2))
     
     
vr=VotingRegressor(estimators)
scores=cross_val_score(vr,x,y,scoring='r2',cv=10)
print("Voting Regressor",np.round(np.mean(scores),2))
